# ==================== Concerto + DINOSAUR 训练配置 ====================
# 使用 Concerto 作为冻结的 point encoder，输出点特征后 FPS 采样，再接 DINOSAUR 训练

# ==================== 模型配置 ====================
model:
  backbone: concerto              # 选择backbone: mask3d / logosp / concerto
  hidden_dim: 768                 # DINOSAUR输入维度（保持与现有代码一致）

  # 采样配置
  num_superpoints: 1024           # FPS采样的token数量

  # DINOSAUR配置
  num_slots: 20
  slot_dim: 256
  slot_att_iter: 5
  query_opt: True
  ISA: True

  # GeoPE 位置编码（替代傅里叶位置编码）
  use_geo_pe: True
  geo_pe_base: 100.0

  # 选择 Decoder：mlp 或 transformer
  decoder_type: transformer          # 或 transformer

  # 仅当 decoder_type=transformer 时生效（可按需调小）
  decoder_tf_layers: 2
  decoder_tf_heads: 8
  decoder_tf_ff_dim: 1024
  decoder_tf_dropout: 0.1

  # ==================== Two-stage Slot Attention (bg/fg -> fg decomposition) ====================
  two_stage: true
  # stage1(2 slots) / stage2(S-1 slots) 的 slot attention 迭代次数（默认可与 slot_att_iter 相同或略小）
  two_stage_stage1_iters: 3
  two_stage_stage2_iters: 3
  # (A) stage1: 背景/前景尺度先验（仅 ISA 生效）
  two_stage_bg_init_scale: 2.0
  two_stage_fg_init_scale: 0.3
  two_stage_bg_init_pos: 0.0
  two_stage_fg_init_pos: 0.0
  # (B) stage1: token 特征均值初始化背景 slot0
  two_stage_stage1_bg_mean_init: true
  # (C) stage1: 背景 slot0 不注入 GeoPE
  two_stage_stage1_bg_no_pe: true

# ==================== 路径配置 ====================
paths:
  # Concerto 权重（本地路径）
  concerto_checkpoint: /home/pbw/data1/3D_PointCloud_Segmentation/PLSG_Net/Model_Code/Model/concerto_base_origin.pth
  # 与 Concerto demo 一致：上采样前两次做 concat
  concerto_concat_levels: 2
  # 若你的环境没有 flash_attn，建议 False（默认 False）
  concerto_enable_flash: True
  # 关闭 flash 时的 patch size（显存不够可调小）
  concerto_enc_patch_size: 1024
  # 如果自动推断 Concerto 输出维度失败，回退用这个（base/large 常用 1088）
  concerto_feat_dim_fallback: 1088

# ==================== 数据配置 ====================
data:
  dataset: s3dis
  # S3DIS 根目录（包含 Area_1 ... Area_6，各 Area 下为 room_name/room_name.txt）
  s3dis_root: /home/pbw/data1/3D_PointCloud_Segmentation/PLSG_Net/dataset/S3DIS/Stanford_Large-Scale_Indoor_Spaces_3D_Dataset/Stanford3dDataset_v1.2_Aligned_Version
  # 训练/验证 Area 划分（常见设置：Area_5 作为验证，其余训练）
  train_areas: [1, 2, 3, 4, 5, 6]
  val_areas: [5]
  # 每个房间重采样到固定点数（S3DIS txt 点数不一，dataloader 会做上/下采样）
  max_points: 80000

# ==================== 训练配置 ====================
train:
  batch_size_per_gpu: 2
  accumulation_steps: 1
  num_workers: 4
  pin_memory: True
  persistent_workers: True
  prefetch_factor: 2

  epochs: 400
  warmup_epochs: 5

  # ======== 两阶段训练（不依赖命令行）========
  # 1) 预训练：前 pretrain_featrec_only_epochs 轮强制只用 feat_rec（其余 loss 权重置 0）
  # 2) 若 stop_after_pretrain=True：到达该轮数后自动保存基线 checkpoint 并退出
  #    然后把 resume_from 指向该 checkpoint，继续训练（此时会按 loss.warmup / loss.weights 生效）
  # 关闭“仅 feat_rec 的预训练阶段”（两阶段训练）
  enable_pretrain_featrec_only: False
  pretrain_featrec_only_epochs: 0
  stop_after_pretrain: False
  resume_from: ""

  grad_clip_norm: 0.5
  use_amp: True
  detect_anomaly: False
  log_grad_details_on_nan: True
  grad_debug_max_params: 5

  optimizer:
    lr: 1.0e-4
    weight_decay: 0.01
    betas: [0.9, 0.999]

  scheduler:
    type: "poly"
    power: 1.2

# ==================== 损失函数权重 ====================
loss:
  # ==================== 无监督语义分割损失（slot-based）====================
  # L = λ_rec L_feat_rec + λ_c L_compact + λ_e L_entropy + λ_min L_min_usage + λ_s L_smooth (+ λ_con L_cons)
  weights:
    feat_rec: 1         # 语义特征重建（MSE）
    compact: 0           # slot 内特征紧致性（余弦紧致，0~1）
    entropy: 0             # 点级低熵（更硬分配）
    min_usage: 0           # 仅惩罚“空/死 slot”（不会强制平均分割）
    smooth: 0            # 可选：边界感知平滑（默认关）
    cons: 0              # 可选：双视角一致性（需要数据管线支持第二视角）
    diversity: 0.2         # slot 多样性（鼓励不同slot学习不同表示）
    # (D) 背景面积正则：鼓励 slot0 覆盖更多 token（谨慎开，小权重起步）
    bg_area: 0.05
  warmup:
    enabled: True
    log_weights: True
    # 以 epoch 为单位：先重建，再逐步打开/增大其它约束项（线性 ramp）
    items:
      # 重建项始终开启
      feat_rec:
        enabled: True
        start_epoch: 0
        warmup_epochs: 0
        start_weight: 1.0
      # 其它项：默认从 0 开始，先学会重建后再逐步细化
      compact:
        enabled: True
        start_epoch: 30
        warmup_epochs: 20
        start_weight: 0.0
      entropy:
        enabled: True
        start_epoch: 3
        warmup_epochs: 10
        start_weight: 0.0
      min_usage:
        enabled: True
        start_epoch: 10
        warmup_epochs: 20
        start_weight: 0.0
      # 若你后续把 smooth/cons 的权重从 0 改大，下面可直接控制开启时机
      smooth:
        enabled: True
        start_epoch: 30
        warmup_epochs: 20
        start_weight: 0.0
      cons:
        enabled: True
        start_epoch: 30
        warmup_epochs: 20
        start_weight: 0.0
      diversity:
        enabled: True
        start_epoch: 60
        warmup_epochs: 20
        start_weight: 0.0
  params:
    # 是否对目标特征 stop-grad（建议 True，避免反向破坏已很好的 encoder 特征空间）
    stop_grad_target: True
    # compact/smooth 中是否对点特征 stop-grad（建议 True）
    stop_grad_compact: True

    # entropy: 点级低熵(更硬分配) + slot负载均衡(防塌缩到单slot)
    # 设为 0 则保持旧行为；建议先从 1.0 起步（若仍偏塌缩可增大，若过度均匀可减小）
    entropy_balance_weight: 0.2

    # compact: 对slot内离群点的敏感度（p越大越像max，离群点更容易把loss拉大）
    # - compact_outlier_p = 1: 等价于平均（不敏感）
    # - 建议 4~12 起步；如果梯度不稳就调小
    compact_outlier_p: 8
    # 对soft分配做锐化 w^gamma，仅让高置信点主导中心方向；若高置信误分离群点，会更强惩罚
    compact_sharpen_gamma: 2.0

    # slot diversity：不同 slot 之间尽量不相似（只惩罚“过于相似”的正相关）
    # loss = mean_{i!=j} relu(cos(sloti,slotj)-margin)^power
    slot_diversity_margin: 0.1
    slot_diversity_power: 2.0

    # min-usage：slot 占用率阈值 rho（比例，0~1）；只惩罚占用 < rho 的 slot
    min_usage_rho: 0.01

    # smooth：基于 superpoint 坐标的 kNN 图 + 可选特征相似度权重 + 可选 entropy gating
    smooth_enabled: False
    smooth_k: 16
    smooth_sigma_x: 0.10
    smooth_sigma_f: 0.50
    smooth_use_feature_weight: True
    smooth_use_entropy_gating: True
    smooth_entropy_gating_power: 1.0
    # (D) 背景面积正则参数：slot0 视作背景；让 mean(mask_bg) 接近该目标比例
    bg_slot_index: 0
    bg_area_target: 0.7
    eps: 1e-8

# ==================== 数据增强 ====================
augmentation:
  rotation_range: [-5, 5]
  scale_range: [0.95, 1.05]
  translation: 0.1
  jitter_sigma: 0.01
  color_jitter: 0.05

# ==================== 分布式训练 ====================
distributed:
  find_unused_parameters: True
  master_port: 29501

# ==================== 验证配置 ====================
validation:
  val_interval: 1
  early_stopping_patience: 20

# ==================== Checkpoint配置 ====================
checkpoint:
  output_dir: /home/pbw/data1/3D_PointCloud_Segmentation/PLSG_Net/Model_Code/src/DINOSAUR/checkpoints/checkpoints_concerto/concerto_s3dis_origin/
  save_interval: 5
  keep_checkpoint_max: 5

# ==================== 可视化配置 ====================
visualization:
  enabled: True              # 是否启用可视化
  save_ply: True             # 是否导出 PLY（slot 分配结果，更轻量）
  num_vis_samples: 3         # 可视化样本数量
  static_timeout_sec: 120    # 静态图超时（秒）

inference:
  export_ply: False
  # 留空则默认使用 checkpoint.output_dir/best_model.pth
  checkpoint_path: "/home/pbw/data1/3D_PointCloud_Segmentation/PLSG_Net/Model_Code/src/DINOSAUR/checkpoints/checkpoints_concerto/concerto_scannet/epoch_105.pth"
  # 从验证集 val_dataset 中选择第几个样本导出
  sample_index: 6
  # 输出 ply 路径；留空则输出到 checkpoint.output_dir 下的 slot_assignment_{sample_index}.ply
  output_ply: "/home/pbw/data1/3D_PointCloud_Segmentation/PLSG_Net/Model_Code/src/DINOSAUR/checkpoints/checkpoints_concerto/concerto_s3dis/visualizations/slot_assignment_0.ply"

# ==================== 其他配置 ====================
seed: 42
device: cuda
gpu_ids: [6,7]
log_interval: 20
