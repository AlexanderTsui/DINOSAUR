# ==================== PointBERT + DINOSAUR 训练配置 ====================
# 基于SPFormer版本改进，使用PointBERT作为特征提取器

# ==================== 模型配置 ====================
model:
  # PointBERT配置
  pointbert_dim: 384              # PointBERT输出维度 (trans_dim)
  pointbert_num_groups: 512       # 超点数量（PointBERT的num_group）
  pointbert_group_size: 32        # 每组点数
  pointbert_input_points: 8192    # 输入点数（PointBERT默认）
  
  # 投影层配置
  projector:
    in_dim: 384                   # PointBERT输出
    out_dim: 768                  # DINOSAUR输入
  
  # DINOSAUR配置
  num_slots: 7                   # Slot数量（略微过分割）
  slot_dim: 256                   # Slot维度
  slot_att_iter: 3                # Slot Attention迭代次数
  query_opt: True                 # 使用可学习的slot初始化
  ISA: True                       # 使用Invariant Slot Attention
  token_num: 512                  # Token数量（与超点数一致）
  num_points: 512                 # 点数（与超点数一致）
  din_feature_dim: 768            # DINOSAUR特征维度（hardcoded）

# ==================== 数据配置 ====================
data:
  # PointBERT权重和配置
  pointbert_checkpoint: /home/pbw/data1/3D_PointCloud_Segmentation/PLSG_Net/Model_Code/Model/ULIP-2-PointBERT-10k-xyzrgb-pc-vit_g-objaverse_shapenet-pretrained.pt
  pointbert_config: /home/pbw/data1/3D_PointCloud_Segmentation/PLSG_Net/Model_Code/src/PointBERT/PointTransformer_8192point.yaml
  
  # S3DIS数据集
  s3dis_root: /home/pbw/data1/3D_PointCloud_Segmentation/PLSG_Net/dataset/S3DIS/Stanford_Large-Scale_Indoor_Spaces_3D_Dataset/Stanford3dDataset_v1.2_Aligned_Version
  train_areas: [1, 2, 3, 4, 6]    # 训练集Area
  val_areas: [5]                  # 验证集Area
  
  # 数据预处理
  target_points: 8192             # 重采样点数（PointBERT输入）
  normalize_xyz: True             # 归一化坐标到单位球
  normalize_rgb: True             # 归一化RGB到[0,1]

# ==================== 训练配置 ====================
train:
  # 批次配置
  batch_size_per_gpu: 64           # 单卡batch size（PointBERT较大，降低bs）
  accumulation_steps: 1           # 梯度累积步数
  num_workers: 8                  # 数据加载进程数
  pin_memory: True
  
  # 训练轮次
  epochs: 120
  warmup_epochs: 10               # 增加warmup（PointBERT特征更强，需要更多warmup）
  
  # 梯度相关
  grad_clip_norm: 0.5             # 梯度裁剪
  use_amp: True                   # 混合精度训练
  
  # 冻结策略
  freeze_pointbert: True          # 冻结PointBERT
  unfreeze_after_epoch: -1        # -1表示始终冻结，>0表示在第N个epoch后解冻
  
  # 优化器
  optimizer:
    lr: 0.0001                    # 学习率（可能需要调整）
    weight_decay: 0.05            # 权重衰减
    betas: [0.9, 0.999]           # Adam beta参数
  
  # 学习率调度器
  scheduler:
    type: "poly"                  # poly衰减
    power: 0.9                    # 衰减指数

# ==================== 损失函数权重 ====================
loss:
  weights:
    reconstruction: 1.0           # w1: MSE重建损失权重
    mask_entropy: 0.2            # w2: Mask熵正则（鼓励确定性分配）
    slot_diversity: 0.2           # w3: Slot多样性损失（防止坍缩）
    mask_sparsity: 0.05           # w4: Mask稀疏性损失
    mask_uniformity: 0.5         # w5: Mask均匀性损失（防止所有点塌缩到单个slot）

# ==================== 数据增强 ====================
augmentation:
  rotation_range: [-8, 8]         # 随机旋转范围（度）
  scale_range: [0.9, 1.1]         # 随机缩放范围
  translation: 0.08               # 随机平移（归一化空间）
  jitter_sigma: 0.01              # 坐标抖动标准差
  color_jitter: 0.05              # RGB颜色抖动

# ==================== 分布式训练 ====================
distributed:
  find_unused_parameters: True    # DDP查找未使用参数

# ==================== 验证配置 ====================
validation:
  val_interval: 1                 # 验证间隔（每N个epoch进行一次验证，记录所有损失项）
  early_stopping_patience: 25     # 早停patience（基于验证总损失）

# ==================== Checkpoint配置 ====================
checkpoint:
  output_dir: /home/pbw/data1/3D_PointCloud_Segmentation/PLSG_Net/Model_Code/src/DINOSAUR/checkpoints_pointbert
  save_interval: 5                # 保存间隔（epochs）
  keep_checkpoint_max: 5          # 最多保留checkpoint数量

# ==================== 其他配置 ====================
seed: 1999
device: cuda
gpu_ids: [5, 6]                   # 使用的GPU ID（物理GPU 1和3）
log_interval: 10                  # 日志打印间隔（iterations）
vis_interval: 500                 # 可视化间隔（iterations）

# ==================== 说明 ====================
# 与SPFormer版本的主要差异:
# 1. batch_size 从8降到6（PointBERT ViT-G更大）
# 2. warmup_epochs 从8增到10（更强的特征需要更多warmup）
# 3. 数据处理更简单（不需要预计算超点标签）
# 4. 特征维度 384 vs 32（投影层负担更重）

