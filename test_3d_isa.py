"""
3D ISAæ¨¡å—æµ‹è¯•å’Œå¯è§†åŒ–è„šæœ¬ï¼ˆå¯é€‰é›†æˆSPFormerï¼‰

ç”¨é€”ï¼š
1. éªŒè¯ä»2Dåˆ°3Dçš„ä¿®æ”¹æ˜¯å¦æ­£ç¡®ï¼ˆæ— é¢„è®­ç»ƒæƒé‡æƒ…å†µä¸‹ï¼‰
2. å¯è§†åŒ–slotåœ¨3Dç©ºé—´ä¸­çš„åˆ†å¸ƒ
3. æ£€æŸ¥æ¨¡å‹çš„å‰å‘ä¼ æ’­ã€æ¢¯åº¦æµåŠ¨å’Œç»´åº¦åŒ¹é…
4. å½“ config.use_spformer = True æ—¶ï¼Œè°ƒç”¨SPFormerç”Ÿæˆè¶…ç‚¹ç‰¹å¾å†è¿›å…¥DINOSAUR

ä½¿ç”¨æ–¹æ³•ï¼š
    ç›´æ¥è¿è¡Œæ­¤è„šæœ¬ï¼špython test_3d_isa.py
    å‚æ•°å¯åœ¨ main å‡½æ•°ä¸­ç›´æ¥ä¿®æ”¹ï¼ˆå« use_spformer å¼€å…³ï¼‰
"""

import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import sys
import os
import importlib

# æ·»åŠ æ¨¡å‹è·¯å¾„
sys.path.append(os.path.dirname(__file__))

try:
    DINOSAURpp = importlib.import_module('models.model').DINOSAURpp
except ModuleNotFoundError:
    sys.path.append(os.path.join(os.path.dirname(__file__), 'models'))
    DINOSAURpp = importlib.import_module('model').DINOSAURpp


class TestConfig:
    """æµ‹è¯•é…ç½®å‚æ•°"""
    def __init__(self):
        # === æ¨¡å¼é€‰æ‹© ===
        self.use_spformer = False     # æ˜¯å¦èµ°SPFormerâ†’DINOSAURæµç¨‹
        
        # === Slot Attention å‚æ•° ===
        self.num_slots = 7           # Slotæ•°é‡
        self.slot_dim = 256          # Slotç‰¹å¾ç»´åº¦
        self.slot_att_iter = 3       # è¿­ä»£æ¬¡æ•°
        self.query_opt = True        # æ˜¯å¦ä¼˜åŒ–Query
        self.ISA = True              # æ˜¯å¦ä½¿ç”¨ISAï¼ˆ3Dä½ç½®ç¼–ç ï¼‰
        
        # === ç‚¹äº‘æ•°æ®å‚æ•° ===
        self.num_points = 1024       # ç‚¹äº‘ç‚¹æ•°
        self.point_feature_dim = 768 # è¾“å…¥ç‰¹å¾ç»´åº¦ (å¿…é¡»ä¸æ¨¡å‹ç¡¬ç¼–ç çš„768åŒ¹é…)
        self.batch_size = 2          # æµ‹è¯•Batchå¤§å°
        self.num_objects = 2         # ç”Ÿæˆæ•°æ®æ—¶çš„æ¨¡æ‹Ÿç‰©ä½“æ•°
        
        # === å…¶ä»–å‚æ•° ===
        self.token_num = self.num_points  # 3Dç‰ˆæœ¬ï¼štoken_num = num_points
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.n_superpoints = 50       # ä½¿ç”¨SPFormeræ—¶çš„è¶…ç‚¹æ•°é‡
        self.spformer_config_path = os.path.join(
            os.path.dirname(__file__), 
            '../SPFormer/configs/spf_scannet.yaml'
        )
        
        # === è¾“å‡ºé…ç½® ===
        self.visualize = True        # æ˜¯å¦ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
        self.output_dir = './visualization/test_results_3d' # ç»“æœä¿å­˜è·¯å¾„


def generate_toy_point_cloud(config):
    """
    ç”Ÿæˆç©å…·ç‚¹äº‘æ•°æ®ç”¨äºæµ‹è¯•
    æ¨¡æ‹Ÿå‡ ä¸ªé«˜æ–¯åˆ†å¸ƒçš„ç°‡ä»£è¡¨ä¸åŒçš„ç‰©ä½“
    """
    print(f"\n{'='*60}")
    print("ç”Ÿæˆç©å…·ç‚¹äº‘æ•°æ®...")
    print(f"{'='*60}")
    
    points_list = []
    features_list = []
    labels_list = []
    
    for b in range(config.batch_size):
        batch_points = []
        batch_features = []
        batch_labels = []
        
        points_per_object = config.num_points // config.num_objects
        
        for obj_id in range(config.num_objects):
            # æ¯ä¸ªç‰©ä½“æ˜¯ä¸€ä¸ª3Dé«˜æ–¯åˆ†å¸ƒçš„ç‚¹äº‘
            center = np.random.randn(3) * 2  # éšæœºä¸­å¿ƒä½ç½®
            scale = np.random.rand() * 0.5 + 0.3  # éšæœºå°ºåº¦
            
            # ç”Ÿæˆåæ ‡
            obj_points = np.random.randn(points_per_object, 3) * scale + center
            
            # ç”Ÿæˆç‰¹å¾ (éšæœºåˆå§‹åŒ–ï¼Œæ¨¡æ‹ŸDINO/ViTè¾“å‡º)
            obj_features = np.random.randn(points_per_object, config.point_feature_dim)
            
            obj_labels = np.ones(points_per_object) * obj_id
            
            batch_points.append(obj_points)
            batch_features.append(obj_features)
            batch_labels.append(obj_labels)
        
        # è¡¥é½å‰©ä½™ç‚¹æ•°
        current_count = points_per_object * config.num_objects
        if current_count < config.num_points:
            diff = config.num_points - current_count
            batch_points.append(np.random.randn(diff, 3))
            batch_features.append(np.random.randn(diff, config.point_feature_dim))
            batch_labels.append(np.zeros(diff) - 1) # å™ªå£°
        
        # ç»„åˆæ‰€æœ‰ç‰©ä½“
        batch_points = np.concatenate(batch_points, axis=0)
        batch_features = np.concatenate(batch_features, axis=0)
        batch_labels = np.concatenate(batch_labels, axis=0)
        
        # éšæœºæ‰“ä¹±é¡ºåºï¼ˆæ¨¡æ‹ŸçœŸå®ç‚¹äº‘æ˜¯æ— åºçš„ï¼‰
        indices = np.random.permutation(config.num_points)
        batch_points = batch_points[indices]
        batch_features = batch_features[indices]
        batch_labels = batch_labels[indices]
        
        points_list.append(batch_points)
        features_list.append(batch_features)
        labels_list.append(batch_labels)
    
    points = torch.FloatTensor(np.stack(points_list, axis=0))
    features = torch.FloatTensor(np.stack(features_list, axis=0))
    labels = torch.LongTensor(np.stack(labels_list, axis=0))
    
    print(f"âœ“ ç‚¹äº‘å½¢çŠ¶: {points.shape}")
    print(f"âœ“ ç‰¹å¾å½¢çŠ¶: {features.shape}")
    print(f"âœ“ æ ‡ç­¾å½¢çŠ¶: {labels.shape}")
    print(f"âœ“ åæ ‡èŒƒå›´: [{points.min():.2f}, {points.max():.2f}]")
    
    return points, features, labels


def generate_toy_data_xyzrgb(config):
    """
    ç”ŸæˆåŒ…å«RGBä¿¡æ¯çš„ç©å…·ç‚¹äº‘ï¼Œä¾›SPFormerç®¡çº¿æµ‹è¯•
    """
    print(f"\n{'='*60}")
    print("ç”Ÿæˆç©å…·ç‚¹äº‘æ•°æ® (XYZ + RGB)...")
    print(f"{'='*60}")
    
    points_per_object = config.num_points // config.num_objects
    xyz_list = []
    rgb_list = []
    
    for obj_id in range(config.num_objects):
        center = np.random.randn(3) * 2
        scale = np.random.rand() * 0.5 + 0.3
        obj_xyz = np.random.randn(points_per_object, 3) * scale + center
        
        obj_rgb = np.random.rand(points_per_object, 3) * 0.2
        obj_rgb[:, obj_id % 3] += 0.8  # ç®€å•èµ‹äºˆä¸»è‰²è°ƒ
        
        xyz_list.append(obj_xyz)
        rgb_list.append(obj_rgb)
    
    xyz = np.concatenate(xyz_list, axis=0)
    rgb = np.concatenate(rgb_list, axis=0)
    
    idx = np.random.permutation(len(xyz))
    xyz = xyz[idx]
    rgb = rgb[idx]
    
    rgb = (rgb - 0.5) * 2  # å½’ä¸€åŒ–åˆ°[-1, 1]
    
    print(f"âœ“ ç‚¹äº‘å½¢çŠ¶: {xyz.shape}")
    print(f"âœ“ RGBå½¢çŠ¶: {rgb.shape}")
    print(f"âœ“ åæ ‡èŒƒå›´: [{xyz.min():.2f}, {xyz.max():.2f}]")
    
    return xyz.astype(np.float32), rgb.astype(np.float32)


class TestSPFormerExtractor:
    """SPFormerç‰¹å¾æå–å™¨ï¼ˆæµ‹è¯•æ¨¡å¼ï¼Œæ— é¢„è®­ç»ƒæƒé‡ï¼‰"""
    def __init__(self, config_path, device='cuda'):
        try:
            gorilla = importlib.import_module('gorilla')
            spformer_model = importlib.import_module('spformer.model')
            spconv = importlib.import_module('spconv.pytorch')
            pointgroup_ops = importlib.import_module('pointgroup_ops')
            torch_scatter = importlib.import_module('torch_scatter')
            scatter_mean = getattr(torch_scatter, 'scatter_mean')
            scatter_max = getattr(torch_scatter, 'scatter_max')
        except ImportError as e:
            raise ImportError("SPFormerä¾èµ–æœªå®‰è£…æˆ–æœªç¼–è¯‘ï¼Œè¯·ç¡®è®¤åå†å¼€å¯use_spformer") from e
        
        if not os.path.exists(config_path):
            raise FileNotFoundError(f"SPFormeré…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        
        self.device = device
        self.gorilla = gorilla
        self.SPFormer = spformer_model.SPFormer
        self.spconv = spconv
        self.pointgroup_ops = pointgroup_ops
        self.scatter_mean = scatter_mean
        self.scatter_max = scatter_max
        
        self.cfg = gorilla.Config.fromfile(config_path)
        
        print(f"\n[SPFormer] æ„å»ºæ¨¡å‹ (éšæœºæƒé‡)...")
        self.model = self.SPFormer(**self.cfg.model).to(device)
        self.model.eval()
        self.output_dim = self.cfg.model.decoder.hidden_dim
        print(f"[SPFormer] è¾“å‡ºç»´åº¦: {self.output_dim}")
    
    def generate_superpoints(self, xyz, rgb, n_clusters=50):
        """ç®€å•å±‚æ¬¡èšç±»ç”Ÿæˆè¶…ç‚¹"""
        from sklearn.cluster import AgglomerativeClustering
        from sklearn.neighbors import kneighbors_graph
        
        print(f"\n[SPFormer] ç”Ÿæˆè¶…ç‚¹ (K={n_clusters})...")
        
        connectivity = kneighbors_graph(xyz, n_neighbors=10, include_self=False)
        cluster = AgglomerativeClustering(
            n_clusters=n_clusters,
            connectivity=connectivity,
            linkage='ward'
        )
        labels = cluster.fit_predict(np.concatenate([xyz, rgb], axis=1))
        print(f"[SPFormer] å®é™…ç”Ÿæˆ {len(np.unique(labels))} ä¸ªè¶…ç‚¹")
        return labels
    
    def prepare_batch(self, xyz, rgb, superpoints):
        """æ•´ç†SPFormeræ‰€éœ€è¾“å…¥"""
        coord_float = torch.from_numpy(xyz).float()
        feat_rgb = torch.from_numpy(rgb).float()
        superpoint = torch.from_numpy(superpoints).long()
        
        voxel_cfg = self.cfg.data.test.voxel_cfg
        scale = voxel_cfg.scale
        
        coord_float_scaled = coord_float * scale
        coord_float_scaled -= coord_float_scaled.min(0)[0]
        coord_long = coord_float_scaled.long()
        
        coords_with_batch = torch.cat([
            torch.zeros(coord_long.shape[0], 1).long(),
            coord_long
        ], dim=1)
        
        feats = torch.cat((feat_rgb, coord_float_scaled), dim=1)
        
        spatial_shape_clip = np.clip(
            (coords_with_batch.max(0)[0][1:] + 1).numpy(),
            voxel_cfg.spatial_shape[0],
            None
        )
        
        voxel_coords, p2v_map, v2p_map = self.pointgroup_ops.voxelization_idx(
            coords_with_batch, 1, 4
        )
        
        batch_offsets = torch.tensor([0, superpoint.max().item() + 1], dtype=torch.int)
        
        return {
            'voxel_coords': voxel_coords.to(self.device),
            'p2v_map': p2v_map.to(self.device),
            'v2p_map': v2p_map.to(self.device),
            'spatial_shape': spatial_shape_clip,
            'feats': feats.to(self.device),
            'superpoints': superpoint.to(self.device),
            'batch_offsets': batch_offsets.to(self.device)
        }
    
    def extract(self, xyz, rgb, superpoints):
        """
        ä½¿ç”¨SPFormeræå–ç‚¹çº§åŠè¶…ç‚¹çº§ç‰¹å¾
        Returns:
            point_features: (N, D)
            sp_feats: (K, D)
        """
        batch = self.prepare_batch(xyz, rgb, superpoints)
        batch_size = len(batch['batch_offsets']) - 1
        
        with torch.no_grad():
            voxel_feats = self.pointgroup_ops.voxelization(
                batch['feats'],
                batch['v2p_map']
            )
            
            input_tensor = self.spconv.SparseConvTensor(
                voxel_feats,
                batch['voxel_coords'].int(),
                batch['spatial_shape'],
                batch_size
            )
            
            x = self.model.input_conv(input_tensor)
            x, _ = self.model.unet(x)
            x = self.model.output_layer(x)
            
            p2v_map = batch['p2v_map'].long()
            if p2v_map.min() < 0:
                valid_mask = p2v_map >= 0
                point_features = torch.zeros(
                    (p2v_map.shape[0], x.features.shape[1]),
                    device=self.device,
                    dtype=x.features.dtype
                )
                if valid_mask.any():
                    point_features[valid_mask] = x.features[p2v_map[valid_mask]]
            else:
                point_features = x.features[p2v_map]
            
            if self.model.pool == 'mean':
                sp_feats = self.scatter_mean(point_features, batch['superpoints'], dim=0)
            else:
                sp_feats, _ = self.scatter_max(point_features, batch['superpoints'], dim=0)
        
        print(f"[SPFormer] ç‚¹ç‰¹å¾: {point_features.shape}")
        print(f"[SPFormer] è¶…ç‚¹ç‰¹å¾: {sp_feats.shape}")
        return point_features, sp_feats


def compute_superpoint_centers(xyz, superpoints):
    """
    è®¡ç®—æ¯ä¸ªè¶…ç‚¹çš„å‡ ä½•ä¸­å¿ƒ
    """
    from torch_scatter import scatter_mean
    
    xyz_tensor = torch.from_numpy(xyz).float()
    sp_tensor = torch.from_numpy(superpoints).long()
    
    sp_coords = scatter_mean(xyz_tensor, sp_tensor, dim=0)
    print(f"[SPFormer] è¶…ç‚¹ä¸­å¿ƒ: {sp_coords.shape}")
    return sp_coords


def prepare_spformer_inputs(config):
    """
    å®Œæ•´çš„SPFormerâ†’DINOSAURè¾“å…¥å‡†å¤‡æµç¨‹
    Returns:
        points: (1, K, 3) torch.FloatTensor
        features: (1, K, D) torch.FloatTensor
        extra_vis: dictï¼Œå¯é€‰å¯è§†åŒ–ä¿¡æ¯
    """
    xyz, rgb = generate_toy_data_xyzrgb(config)
    
    extractor = TestSPFormerExtractor(
        config.spformer_config_path,
        device=config.device
    )
    
    superpoints = extractor.generate_superpoints(
        xyz, rgb,
        n_clusters=config.n_superpoints
    )
    
    _, sp_feats = extractor.extract(xyz, rgb, superpoints)
    sp_coords = compute_superpoint_centers(xyz, superpoints)
    
    if sp_feats.shape[1] != config.point_feature_dim:
        print(f"[SPFormer] ç‰¹å¾ç»´åº¦ä¸åŒ¹é…: {sp_feats.shape[1]} â†’ {config.point_feature_dim}")
        projector = nn.Linear(sp_feats.shape[1], config.point_feature_dim).to(config.device)
        sp_feats = projector(sp_feats)
    
    points = sp_coords.unsqueeze(0).cpu()
    features = sp_feats.unsqueeze(0).detach().cpu()
    
    extra_vis = {
        'xyz': xyz,
        'rgb': rgb,
        'superpoints': superpoints
    }
    
    return points, features, extra_vis


def normalize_point_coords(points):
    """
    å°†ç‚¹äº‘åæ ‡å½’ä¸€åŒ–åˆ°[-1, 1]èŒƒå›´
    è¿™æ˜¯ISAæ¨¡å—æ‰€å¿…éœ€çš„é¢„å¤„ç†æ­¥éª¤
    """
    print(f"\n{'='*60}")
    print("å½’ä¸€åŒ–ç‚¹äº‘åæ ‡...")
    print(f"{'='*60}")
    
    # åŸºäºBatchå†…æ‰€æœ‰ç‚¹çš„è¾¹ç•Œæ¡†å½’ä¸€åŒ–
    batch_min = points.min(dim=1, keepdim=True)[0]  # (B, 1, 3)
    batch_max = points.max(dim=1, keepdim=True)[0]  # (B, 1, 3)
    
    # å½’ä¸€åŒ–åˆ° [0, 1]
    normalized = (points - batch_min) / (batch_max - batch_min + 1e-8)
    # æ˜ å°„åˆ° [-1, 1]
    normalized = normalized * 2 - 1
    
    print(f"âœ“ å½’ä¸€åŒ–å®Œæˆï¼ŒèŒƒå›´: [{normalized.min():.3f}, {normalized.max():.3f}]")
    
    return normalized


def test_model_forward(model, points, features, config):
    """
    æµ‹è¯•æµç¨‹æ ¸å¿ƒï¼šæ¨¡å‹å‰å‘ä¼ æ’­ä¸éªŒè¯
    """
    print(f"\n{'='*60}")
    print("å¼€å§‹æ¨¡å‹æµ‹è¯•æµç¨‹")
    print(f"{'='*60}")
    
    # 1. å½¢çŠ¶éªŒè¯
    print("\n[æ­¥éª¤1] å½¢çŠ¶éªŒè¯...")
    try:
        with torch.no_grad():
            reconstruction, slots, masks = model(features, points)
            
        print(f"  è¾“å…¥ç‰¹å¾: {features.shape}")
        print(f"  è¾“å…¥åæ ‡: {points.shape}")
        print(f"  è¾“å‡ºé‡å»º: {reconstruction.shape}")
        print(f"  è¾“å‡ºSlots: {slots.shape}")
        print(f"  è¾“å‡ºMasks: {masks.shape}")
        
        assert reconstruction.shape == (config.batch_size, config.num_points, 768), "é‡å»ºå½¢çŠ¶é”™è¯¯"
        assert slots.shape == (config.batch_size, config.num_slots, config.slot_dim), "Slotså½¢çŠ¶é”™è¯¯"
        assert masks.shape == (config.batch_size, config.num_slots, config.num_points), "Maskså½¢çŠ¶é”™è¯¯"
        print("  âœ… å½¢çŠ¶éªŒè¯é€šè¿‡")
        
    except Exception as e:
        print(f"  âŒ å½¢çŠ¶éªŒè¯å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False, None, None, None

    # 2. æ¢¯åº¦æµåŠ¨éªŒè¯
    print("\n[æ­¥éª¤2] æ¢¯åº¦æµåŠ¨éªŒè¯...")
    try:
        features_grad = features.clone().requires_grad_(True)
        # æ³¨æ„ï¼špointsé€šå¸¸ä¸éœ€è¦æ¢¯åº¦ï¼Œå› ä¸ºå®ƒæ˜¯è¾“å…¥åæ ‡
        
        model.zero_grad()
        reconstruction, slots, masks = model(features_grad, points)
        
        # æ„å»ºä¸€ä¸ªç®€å•çš„æŸå¤±å‡½æ•°
        loss = reconstruction.sum() + slots.sum()
        loss.backward()
        
        has_grad = features_grad.grad is not None
        grad_norm = features_grad.grad.norm().item() if has_grad else 0
        
        print(f"  ç‰¹å¾æ¢¯åº¦å­˜åœ¨: {has_grad}")
        print(f"  æ¢¯åº¦èŒƒæ•°: {grad_norm:.4f}")
        
        assert has_grad, "æ¢¯åº¦æœªåå‘ä¼ æ’­åˆ°è¾“å…¥ç‰¹å¾"
        assert grad_norm > 0, "æ¢¯åº¦ä¸ºé›¶ï¼Œå¯èƒ½å­˜åœ¨æ–­å¼€çš„è®¡ç®—å›¾"
        print("  âœ… æ¢¯åº¦éªŒè¯é€šè¿‡")
        
    except Exception as e:
        print(f"  âŒ æ¢¯åº¦éªŒè¯å¤±è´¥: {e}")
        return False, None, None, None

    # 3. Slotå±æ€§æ£€æŸ¥ (ä»…åœ¨ISAæ¨¡å¼ä¸‹)
    print("\n[æ­¥éª¤3] Slotå±æ€§æ£€æŸ¥...")
    if config.ISA:
        try:
            with torch.no_grad():
                # è·å–å†…éƒ¨attentionå’Œslotå‚æ•°
                slots_enc, attn = model.slot_encoder(features, points)
                
                # æ‰‹åŠ¨è®¡ç®—Slotä¸­å¿ƒ (S_p) ç”¨äºéªŒè¯
                attn_expanded = attn.unsqueeze(2)  # (B, S, 1, N)
                abs_grid = points.unsqueeze(1).expand(config.batch_size, config.num_slots, config.num_points, 3)
                
                # åŠ æƒå¹³å‡ä½ç½®
                S_p = torch.einsum('bsjd,bsij->bsd', abs_grid, attn_expanded)
                
                # æ£€æŸ¥å¤šæ ·æ€§
                diversity = S_p.std(dim=1).mean().item()
                print(f"  Slotç©ºé—´åˆ†å¸ƒå¤šæ ·æ€§(Std): {diversity:.4f}")
                
                if diversity < 0.01:
                    print("  âš ï¸  è­¦å‘Š: Slotä¸­å¿ƒèšé›†åœ¨ä¸€èµ·ï¼Œå¯èƒ½æ˜¯åˆå§‹åŒ–é—®é¢˜ï¼ˆä½†åœ¨æ— è®­ç»ƒæƒé‡ä¸‹å±æ­£å¸¸ç°è±¡ï¼‰")
                else:
                    print("  âœ… Slotåˆ†å¸ƒå…·æœ‰ä¸€å®šçš„ç©ºé—´å·®å¼‚")
                    
        except Exception as e:
            print(f"  âŒ Slotå±æ€§æ£€æŸ¥å¤±è´¥: {e}")
            pass # ä¸ä¸­æ–­æµç¨‹

    return True, reconstruction, slots, masks


def visualize_results(points, masks, slots, save_dir, extra=None):
    """
    ç”Ÿæˆå¯è§†åŒ–ç»“æœ
    """
    print(f"\n{'='*60}")
    print("ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š")
    print(f"{'='*60}")
    
    extra = extra or {}
    
    # å¦‚æœæä¾›äº†åŸå§‹xyz/rgb/è¶…ç‚¹ä¿¡æ¯ï¼Œåˆ™ç”Ÿæˆæ›´ä¸°å¯Œçš„å¯è§†åŒ–
    if extra.get('xyz') is not None and extra.get('superpoints') is not None:
        visualize_spformer_results(extra, masks, save_dir)
        return
    
    os.makedirs(save_dir, exist_ok=True)
    
    # å–ç¬¬ä¸€ä¸ªæ ·æœ¬
    points_np = points[0].cpu().numpy()
    masks_np = masks[0].detach().cpu().numpy() # (S, N)
    
    num_slots = masks_np.shape[0]
    
    # ç”Ÿæˆæ¯ä¸ªSlotçš„ä¸“å±é¢œè‰²
    if num_slots <= 10:
        cmap = plt.get_cmap('tab10')
        colors_lookup = np.array([cmap(i) for i in range(num_slots)])
    elif num_slots <= 20:
        cmap = plt.get_cmap('tab20')
        colors_lookup = np.array([cmap(i) for i in range(num_slots)])
    else:
        # å¦‚æœslotå¤ªå¤šï¼Œä½¿ç”¨hsvå‡åŒ€åˆ†å¸ƒ
        cmap = plt.get_cmap('hsv')
        colors_lookup = np.array([cmap(i / num_slots) for i in range(num_slots)])
    
    # 1. Slot Assignment å¯è§†åŒ–
    fig = plt.figure(figsize=(15, 6))
    
    # å·¦å›¾ï¼šç‚¹äº‘
    ax1 = fig.add_subplot(121, projection='3d')
    ax1.scatter(points_np[:, 0], points_np[:, 1], points_np[:, 2], s=5, c='gray', alpha=0.5)
    ax1.set_title('Input Point Cloud')
    ax1.set_xlabel('X')
    ax1.set_ylabel('Y')
    ax1.set_zlabel('Z')
    
    # å³å›¾ï¼šSlotåˆ†é… (Argmax)
    ax2 = fig.add_subplot(122, projection='3d')
    slot_ids = masks_np.argmax(axis=0) # (N,)
    
    # æ ¹æ®Slot IDæ˜ å°„é¢œè‰²
    point_colors = colors_lookup[slot_ids]
    
    scatter = ax2.scatter(points_np[:, 0], points_np[:, 1], points_np[:, 2], s=10, c=point_colors)
    ax2.set_title(f'Slot Assignment (Total {num_slots} Slots)')
    ax2.set_xlabel('X')
    ax2.set_ylabel('Y')
    ax2.set_zlabel('Z')
    
    # æ·»åŠ Legend
    from matplotlib.lines import Line2D
    legend_elements = [Line2D([0], [0], marker='o', color='w', label=f'Slot {i}',
                          markerfacecolor=colors_lookup[i], markersize=8)
                   for i in range(num_slots)]
    
    # å°†Legendæ”¾åœ¨å›¾å¤–
    ax2.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(1.05, 1.0), title="Slots")
    
    plt.tight_layout()
    save_path = os.path.join(save_dir, 'visualization.png')
    plt.savefig(save_path, bbox_inches='tight', dpi=150)
    plt.close()
    
    print(f"âœ“ å¯è§†åŒ–å·²ä¿å­˜: {save_path}")


def visualize_spformer_results(extra, slot_masks, save_dir):
    """
    ä½¿ç”¨SPFormeræ•°æ®çš„ä¸‰è§†å›¾å¯è§†åŒ–
    """
    os.makedirs(save_dir, exist_ok=True)
    
    xyz = extra['xyz']
    rgb = extra.get('rgb')
    superpoints = extra['superpoints']
    
    if torch.is_tensor(slot_masks):
        slot_masks = slot_masks.detach().cpu().numpy()
    if torch.is_tensor(superpoints):
        superpoints = superpoints.cpu().numpy()
    
    sp_slot_ids = slot_masks[0].argmax(axis=0)
    point_slot_ids = sp_slot_ids[superpoints]
    num_slots = slot_masks.shape[1]
    
    if num_slots <= 10:
        cmap = plt.get_cmap('tab10')
        colors_lookup = np.array([cmap(i) for i in range(num_slots)])
    elif num_slots <= 20:
        cmap = plt.get_cmap('tab20')
        colors_lookup = np.array([cmap(i) for i in range(num_slots)])
    else:
        cmap = plt.get_cmap('hsv')
        colors_lookup = np.array([cmap(i / num_slots) for i in range(num_slots)])
    
    fig = plt.figure(figsize=(18, 6))
    
    ax1 = fig.add_subplot(131, projection='3d')
    rgb_vis = np.clip((rgb + 1) / 2, 0, 1)
    ax1.scatter(xyz[:, 0], xyz[:, 1], xyz[:, 2], s=2, c=rgb_vis, alpha=0.5)
    ax1.set_title('Input Point Cloud (RGB)')
    ax1.set_xlabel('X')
    ax1.set_ylabel('Y')
    ax1.set_zlabel('Z')
    
    ax2 = fig.add_subplot(132, projection='3d')
    unique_sp = np.unique(superpoints)
    sp_colors = plt.cm.nipy_spectral(np.linspace(0, 1, len(unique_sp)))
    np.random.shuffle(sp_colors)
    point_sp_colors = sp_colors[superpoints]
    ax2.scatter(xyz[:, 0], xyz[:, 1], xyz[:, 2], s=2, c=point_sp_colors, alpha=0.5)
    ax2.set_title(f'Superpoints (K={len(unique_sp)})')
    ax2.set_xlabel('X')
    ax2.set_ylabel('Y')
    ax2.set_zlabel('Z')
    
    ax3 = fig.add_subplot(133, projection='3d')
    point_slot_colors = colors_lookup[point_slot_ids]
    ax3.scatter(xyz[:, 0], xyz[:, 1], xyz[:, 2], s=2, c=point_slot_colors, alpha=0.5)
    ax3.set_title(f'Slot Assignment (Total {num_slots} Slots)')
    ax3.set_xlabel('X')
    ax3.set_ylabel('Y')
    ax3.set_zlabel('Z')
    
    from matplotlib.lines import Line2D
    legend_elements = [
        Line2D([0], [0], marker='o', color='w', label=f'Slot {i}',
               markerfacecolor=colors_lookup[i], markersize=8)
        for i in range(num_slots)
    ]
    ax3.legend(handles=legend_elements, loc='upper left',
               bbox_to_anchor=(1.05, 1.0), title="Slots")
    
    plt.tight_layout()
    save_path = os.path.join(save_dir, 'visualization_spformer_dinosaur.png')
    plt.savefig(save_path, bbox_inches='tight', dpi=150)
    plt.close()
    print(f"âœ“ å¯è§†åŒ–å·²ä¿å­˜: {save_path}")


def main():
    # 1. é…ç½®
    config = TestConfig()
    extra_vis = {}
    
    print(f"æµ‹è¯•é…ç½®:")
    print(f"  - ISAæ¨¡å¼: {config.ISA}")
    print(f"  - Slotæ•°é‡: {config.num_slots}")
    print(f"  - ç‰¹å¾ç»´åº¦: {config.point_feature_dim}")
    print(f"  - ä½¿ç”¨SPFormer: {config.use_spformer}")
    
    # 2. å‡†å¤‡æ•°æ®
    if config.use_spformer:
        try:
            points, features, extra_vis = prepare_spformer_inputs(config)
            config.batch_size = 1
            config.num_points = features.shape[1]
            config.token_num = config.num_points
            print(f"  - SPFormerç”Ÿæˆçš„è¶…ç‚¹æ•°é‡: {config.num_points}")
        except Exception as e:
            print(f"âŒ SPFormeræ•°æ®å‡†å¤‡å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return
    else:
        points, features, labels = generate_toy_point_cloud(config)
    
    points_norm = normalize_point_coords(points)
    
    # 3. åˆå§‹åŒ–æ¨¡å‹
    print(f"\n{'='*60}")
    print("åˆå§‹åŒ–æ¨¡å‹...")
    print(f"{'='*60}")
    try:
        model = DINOSAURpp(config)
        model.eval() # é»˜è®¤ä¸ºevalæ¨¡å¼ï¼Œä½†æµ‹è¯•æ¢¯åº¦æ—¶éœ€è¦æ³¨æ„
        print("âœ“ æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
        return

    # 4. è¿è¡Œæµ‹è¯•
    success, recon, slots, masks = test_model_forward(model, points_norm, features, config)
    
    if success:
        print(f"\n{'='*60}")
        print("ğŸ‰ æ¨¡å—æµ‹è¯•é€šè¿‡ï¼é€»è¾‘é€šè·¯æ­£å¸¸ã€‚")
        print(f"{'='*60}")
        
        if config.visualize:
            visualize_results(points_norm, masks, slots, config.output_dir, extra_vis)
    else:
        print(f"\n{'='*60}")
        print("âš ï¸ æµ‹è¯•å‘ç°é—®é¢˜ï¼Œè¯·æ£€æŸ¥æ—¥å¿—ã€‚")
        print(f"{'='*60}")

if __name__ == '__main__':
    main()
